# 系统操作说明

## 1.人脸注册

- 将含有单独人脸的注册图片重命名为id+后缀名，放入pic_register文件夹内

## 2.语音注册

- 录制多段自己的说话语音，放入.\model\Sperker_recognition\Speaker_wave。然后修改.\model\Sperker_recognition\speaker.txt，格式为

- 说话人名 语音文件路径 例如：

- LONG ./model/Sperker_recognition/Speaker_wave/woziji-1.wav

- 修改loop.py第66行name为说话人名

- 可将loop.py第66行vaw_result修改为自定义唤醒词

## 3.小车启动准备

### 无屏幕方式

- 将电脑热点名称修改为ZHUOLAPTOP，密码修改为zhuoZ0313。开启电脑热点

- 将树莓派连接电源，按下小车电源按钮

- 等待树莓派自动连接电脑热点，在电脑热点处查看树莓派IP地址

- 在VNC Viewer中，输入树莓派IP地址，等待连接

- 输入树莓派账号：LONG，密码：1821863716，连接至树莓派，即可无线观看并操控树莓派屏幕

### 有屏幕方式（未经测试）

- 有线连接屏幕、键盘和鼠标

- 将树莓派连接电源，按下小车电源按钮

- 等待树莓派启动即可

## 4.启动小车系统

- 打开树莓派内命令行

- 输入source car/bin/activate激活虚拟环境

- 输入cd /home/LONG/car_final进入系统目录

- 输入python run.py启动系统

## 5.系统执行流程

- 进入系统，待人脸识别框弹出后，将注册人脸正对摄像头，耐心等待人脸识别完成，识别完成时人脸识别框自动关闭

- 等待命令行输出"欢迎进入智能小车控制系统"或语音TTS"欢迎进入智能小车控制系统"，即成功进入系统

- 用注册语音说出语音唤醒词（默认为“小车小车”）

- 等待命令行输出"我在，随时为您待命"或语音TTS"我在"，即成功唤醒系统

- 唤醒系统后，可以语音启用目标跟踪功能、自动避障功能或语音操控小车运动

## 6.目标跟踪

- 系统处于唤醒状态时，语音说出"目标跟踪"以进入目标跟踪功能

- 此时将弹出摄像头框检测人脸位置及大小，当人脸过小时，小车自动向前移动；当人脸过大时，小车自动向后移动，当人脸在画面偏左/画面偏右时，小车自动向右/左转动

- 处于目标跟踪功能时，语音说出"退出目标跟踪"以退出该功能，小车将重新处于唤醒状态

## 6.目标跟踪

- 系统处于唤醒状态时，语音说出"目标跟踪"以进入目标跟踪功能。成功进入时命令行会打印"开始目标跟踪"并TTS"开始目标跟踪"

- 此时将弹出摄像头框检测人脸位置及大小，当人脸过小时，小车自动向前移动；当人脸过大时，小车自动向后移动，当人脸在画面偏左/画面偏右时，小车自动向右/左转动

- 处于目标跟踪功能时，语音说出"退出目标跟踪"以退出该功能。成功退出时命令行会打印"已关闭目标跟踪"并TTS"已关闭目标跟踪"。小车将重新处于唤醒状态

## 7.自动避障

- 系统处于唤醒状态时，语音说出"自动避障"以进入自动避障功能。成功进入时命令行会打印"开启自动避障模式"并TTS"开启自动避障模式"

- 此时小车将持续检测前方的物体，若左/右侧有物体则小车向右/左转动，若前方有物体则小车自动向后移动

- 处于自动避障功能时，语音说出"关闭自动避障"以退出该功能。成功退出时命令行会打印"已退出自动避障模式"并TTS"已退出自动避障模式"。小车将重新处于唤醒状态

## 8.语音操控小车运动

- 系统处于唤醒状态时，小车可以接受"前进", "后退", "左转", "右转", "加速", "减速", "停车"等语音指令，并执行相应动作

## 9.系统休眠与退出

- 系统长时间未收到指令或收到语音指令"休眠"时，将进入休眠状态，命令行输出"进入休眠状态......"并语音TTS"进入休眠状态"。此时需要再次进行语音唤醒以唤醒系统

- 语音说出"退出系统"以退出小车系统

# 代码说明

## 1.car.py

主程序，流程详见系统操作说明

## 2.Car_move.py

电机小车运动控制程序，控制小车前进、后退、转弯等

 **运动函数定义**
   - `forward(speed)`：前进，参数为速度（占空比）。
   - `backward(speed)`：后退，参数为速度（占空比）。
   - `turn(speed_left_forward=0, speed_left_backward=0, speed_right_forward=0, speed_right_backward=0)`：转弯，四个参数分别为两个左轮前进速度、左轮后退、右轮前进速度、右轮后退的速度。如左转可使用 `turn(0,0,50,0)`等等可自由调节参数控制
   - `stop()`：小车停车。
   - `stop_all()`：停止所有电机并清理GPIO。


## 3.Car_control.py

该程序用于处理语音指令中用于控制小车运动的指令，如：前进指令、后退指令、左转指令等等

**小车命令控制函数**
   - `car_control(command)`：截取读取的语音识别命令的前5个字符，并根据 `COMMANDS` 字典执行相应的命令或反馈无效指令。
     - 如果命令匹配，将调用 `execute_command(action)` 和`Car_move.py`中的控制函数控制小车运动
     - 如果命令无效，将调用 `tts` 模块反馈 "无效指令"。


## 4.ASR.py
语音识别程序，实现实时语音识别功能，带端点检测，自动检测语音开始结束。

**导入模型文件，创建带端点检测的实时语音识别器**
   - `create_recognizer()`：配置模型文件路径、解码方法和端点检测规则。模型文件可由新一代Kaldi官网下载。创建并返回一个语音识别器实例。
   - 其中参数 `enable_endpoint_detection=True` 表示启用语音端点检测，根据规则自动检测语音起始。
    
**语音端点检测规则**

* 当触发这些规则时，自动判定为一句话的开始或者结尾
   - rule1_min_trailing_silence=0.5,  #规则1: 一句话开始前的最短静音时间
   - rule2_min_trailing_silence=0.5, #规则2：两句话之间的最短静音时间，超过这个时间自动区分为两句话。
   - rule3_min_utterance_length=5, #规则3：一句话最长语音时间，单位s，达到最长时间，自动截断语音。

**实时语音识别函数**
   - `realTime_ASR()`：使用麦克风输入进行实时语音识别。
     - 打开音频输入流，循环读取音频数据并进行语音识别并实时打印输出识别结果。
     - 检查端点检测，如果检测到端点且有识别结果，则函数返回全部结果。
     - 如果超过30秒未检测到语音活动，则重置识别器并返回提示信息。


## 5. VAW.py语音唤醒文件
基于VAD+说话人识别+关键词检测实现语音唤醒，vaw()返回两个值：一个说话人的身份，一个关键词检测结果

**创建关键字检测识别器**
   - `create_recognizer()`：创建并返回一个关键词检测实例，配置模型文件路径。
   - 可检测的关键词需自定义，所有可检测的关键词以及其形式存放在模型目录下一个名为`keywords.txt`文件中，
   - 如果想添加自己想要识别的关键词，需要先把关键词进行格式转换然后将转换后的格式存放在`keywords.txt`文件中即可识别该关键词，运行如下命令进行格式转换 . 
       ```
       sherpa-onnx-cli text2token input.txt output.txt --tokens-type ppinyin --tokens tokens.txt
       ```
       其中，`input.txt`中存放你想要识别的关键词如“小车小车 @小车小车” `output.txt`则输出转换后的格式"x iǎo ch ē x iǎo ch ē @小车小车"然后将其添加到`keywords.txt`文件中即可识别。 `tokens.txt`文件是关键词检测KWS模型目录下的词汇文件

**加载说话人嵌入模型**
   - `load_speaker_embedding_model()`：配置说话人什么识别模型文件路径。
   - 说话人身份以及其对应的音频路径被存储放在说话人识别模型目录下一个名为`speaker.txt`的文件中
   - 为了使该模型识别到更多身份人信息，可以向`speaker.txt`文件中加入更多身份人信息，并在对应路径附上对应身份人音频。同时可通过调节阈值参数`threshold`来调整识别效果。

**语音活动检测与关键字检测函数`vaw()`**
   - 使用麦克风输入和VAD模型进行实时语音活动检测和关键字检测。
   - 读取音频数据并进行语音活动检测。
   - 处理语音段，计算说话人并搜索说话人。
   - 进行关键字检测并返回识别结果。


## 6. TTS.py语音合成文件
基于新一代kaldi：Sherpa-onnx模型实现语音合成

**文本转语音函数 `tts()`**
   - `tts(text, sid=1, speed=1.5)`：接受文本作为参数，生成对应的语音输出。
   - 调用模型的 `generate` 方法生成语音，指定语速（speed）和音频片段编号（sid），调整`sid`的编号可改变输出音频的音色，调整`speed`可改变输出音频的语速。
   - 将生成的音频数据写入 WAV 文件，并调用 `play_sound` 播放该文件。


## 7. Ultrasonic_ranging.py

**超声波测距类 `Ultrasoic_wave`**
   - 初始化方法 `__init__`：
     - 设置触发引脚 (`GPIO_trigger`) 和接收引脚 (`GPIO_receive`)。
     - 将触发引脚设置为输出，接收引脚设置为输入。
     - 初始化移动平均距离 (`dist_average`)。
   
   - 方法 `DistMeasure`：
     - 实现超声波测距功能。
     - 发送一个短脉冲信号以触发超声波传感器。
     - 根据声波的速度和时间公式计算距离。
     - 如果超时未收到回音则返回距离 0。
   
   - 方法 `DistMeasure_MovingAverage`：
     - 基于滑动平均法提升测量准确性。
     - 调用 `DistMeasure` 方法获取当前测量的距离。
     - 如果未收到有效距离，则返回之前的移动平均距离。
     - 否则，根据当前测量值通过加权更新移动平均距离并返回。


## 8. Infrared_ray.py

**红外线传感器类 `Infrared`**
   - 初始化方法 `__init__`：
     - 定义了四个引脚分别用于避障传感器和巡线传感器。
     - 分别为右侧避障 (`GPIO_obstacle_right`)、左侧避障 (`GPIO_obstacle_left`)、左侧巡线 (`GPIO_line_left`)、右侧巡线 (`GPIO_line_right`)。
     - 将这些引脚设置为输入模式。

   - 方法 `obstacleMeasure`：
     - 读取避障传感器的状态，返回一个列表 `[left_obstacle, right_obstacle]`。
     - `left_obstacle` 和 `right_obstacle` 的值为 0 表示检测到障碍物，为 1 表示未检测到障碍物。

   - 方法 `lineMreasure`：
     - 读取巡线传感器的状态，返回一个列表 `[left_line, right_line]`。
     - `left_line` 和 `right_line` 的值为 0 或 1，表示传感器是否检测到线路。

## 9. Auto_avoid.py

**自动避障程序 `auto_avoidance()`**
   - 函数开始时，通过`Infrared_ray`和`Ultrasonic_ranging`获取当前的左右障碍物状态和超声波测距的移动平均距离。

   - 根据条件判断是否需要避障：
     - 如果超声波测得的距离小于 20 厘米 (`distance < 0.2`) 或者左右任一侧的红外线传感器检测到障碍物 (`left_obstacle == 0` 或 `right_obstacle == 0`)，则执行避障动作：
       - 停止小车 (`Car_move.stop()`) 并等待 0.5 秒。
       - 根据障碍物的位置选择不同的避障策略：
         - 若左侧有障碍物而右侧无障碍物，执行左转避开左侧障碍物。
         - 若右侧有障碍物而左侧无障碍物，执行右转避开右侧障碍物。
         - 若前方有障碍物，先后退再右转避开。
     - 如果没有障碍物，则直接前进 (`Car_move.forward(50)`)。

   - 每次执行完避障动作后，程序暂停 0.1 秒 (`time.sleep(0.1)`)，然后继续下一次循环。

## 10.face_detect_task.py

该文件实现了人脸检测和人脸注册的功能，使用了多种人脸识别模块。

### 模块初始化

初始化了各种人脸检测和识别模块，包括 YOLOv8 人脸检测器、面部关键点检测、面部识别、特征搜索、人脸注册等。

### 重置函数

- `reset_face_registery()`: 清空人脸注册表。
- `reset_record()`: 清空人脸识别记录数据库。

### 人脸检测任务类

**FaceDetectionTask 类**

继承自 `QRunnable`，实现了人脸检测和识别功能。

**主要方法**

- `__init__(self, signal, record_signal)`: 初始化任务，设置信号和停止标志。
- `stop(self)`: 停止任务。
- `__del__(self)`: 析构函数，确保任务停止。
- `recognize_callback(self, record: RecognizeRecord)`: 识别回调函数，发送识别记录信号。
- `run(self)`: 运行任务，执行人脸检测和识别逻辑，包括跟踪、识别和绘制检测结果。

### 人脸注册任务类

**FaceRegisterTask 类**

继承自 `QRunnable`，实现了人脸注册功能。

**主要方法**

- `__init__(self, image_folder, signal)`: 初始化任务，设置图像文件夹和信号。
- `register_progress(self, i, total)`: 注册进度回调函数，发送注册进度信号。
- `run(self)`: 运行任务，执行人脸注册逻辑，从指定文件夹中读取图像并进行注册。

### 功能简介

1. **FaceDetectionTask 类**
   - 实现了人脸检测和识别功能。
   - 使用 YOLOv8 进行人脸检测，使用特征搜索进行人脸识别。
   - 实时处理视频帧并在图像上绘制检测结果。
   - 通过信号机制将处理结果发送到主线程进行显示。

2. **FaceRegisterTask 类**
   - 实现了批量人脸注册功能。
   - 从指定的文件夹中读取人脸图像并进行注册。
   - 在注册过程中通过信号机制报告进度。

## 11.face_tracker.py

实现了人脸跟踪模块，使用 YOLOv8 进行人脸检测，并使用 SORT 算法进行跟踪。

### 模块初始化

初始化了人脸检测器、面部关键点检测器和跟踪器。

### 跟踪器类

**Tracker 类**

- `__init__(self, detector: BaseModel, max_age=1, min_hits=3, iou_threshold=0.3)`: 初始化跟踪器，设置检测器和 SORT 跟踪器的参数。
- `track(self, frame)`: 对输入帧进行人脸检测和跟踪，返回当前帧中的跟踪器列表和被移除的跟踪器列表。

### 人脸跟踪函数

**face_track**

- 初始化摄像头和人脸检测器。
- 循环读取图像帧，进行人脸检测和跟踪。
- 在图像上绘制检测结果和跟踪 ID。
- 根据跟踪 ID 和框的位置、宽度返回特定值，用于进一步处理。

## 12.Picamera2_Img_et.py

该文件实现了使用 Picamera2 获取图像帧的功能。

### 类定义

**Imget 类**

负责初始化摄像头并获取图像帧。

### 方法

- `__init__(self)`: 初始化 Picamera2 摄像头，设置预览配置，包括图像尺寸、格式、帧率等，并启动摄像头。
- `getImg(self)`: 捕获当前图像帧并返回。
- `__del__(self)`: 停止并关闭摄像头，确保资源释放。

此类提供了一个简单的接口，用于在其他模块中获取实时图像帧。

## 13.run.py

应用程序的入口，负责初始化主窗口和启动人脸检测和注册任务。

### 导入库

导入了必要的库和模块，包括 PySide6 库、OpenCV、NumPy 以及自定义的任务和模块。

### 主窗口类

**MainWindow 类**

继承自 `QtWidgets.QMainWindow` 和自定义的 `Ui_MainWindow`，实现了应用程序的主要逻辑。

**主要方法**

- `__init__(self)`: 初始化主窗口，设置定时器、信号和线程池，检查并清空数据库，启动注册任务和打开摄像头。
- `check_clear_databases(self)`: 清空注册库和记录库。
- `start_register_task(self, folderpath)`: 启动人脸注册任务。
- `open_usb_camera(self)`: 打开本地摄像头。
- `start_playing(self)`: 启动人脸检测任务。
- `stop_playing(self)`: 停止人脸检测任务。

**信号槽**

- `update_frame(self, pixmap)`: 更新显示的图像帧。
- `update_register_progress(self, text)`: 更新注册进度。
- `update_record(self, record: RecognizeRecord)`: 处理识别记录，发出识别信号。
- `handle_face_recognized(self, recognized)`: 处理人脸识别事件。

### 应用程序入口

在 `__main__` 模块中，初始化应用程序，创建主窗口并显示，进入事件循环，检测到注册人脸后启动 `loop.py` 脚本。

## 14.loop.py

该文件是智能小车控制系统的主控制程序，实现了自动避障和目标追踪功能，通过语音指令进行控制。

### 导入库

导入了必要的模块和函数，包括语音识别、语音唤醒、语音合成、自动避障、人脸跟踪和小车控制等功能。

### 全局变量

- `auto_avoid_exit`: 控制自动避障功能的标志。
- `tracking_exit`: 控制目标追踪功能的标志。

### 自动避障函数

**auto_avoid**

实现自动避障功能，通过不断调用 `auto_avoidance` 函数来检测和避开障碍物。

### 目标追踪函数

**tracking**

实现目标追踪功能，通过调用 `face_track` 函数获取小车的移动指令并控制小车的运动方向。

### 主函数

**main**

主控制函数，包含以下功能：

1. 语音唤醒：通过语音唤醒模块唤醒系统。
2. 等待语音指令：通过语音识别模块接收并处理语音指令。
3. 控制自动避障和目标追踪：根据指令启动或停止自动避障和目标追踪功能。
4. 系统退出：根据指令退出系统并清理资源。

### 程序入口

在 `__main__` 模块中，调用 `main` 函数启动系统，通过 `try-except-finally` 结构确保系统异常退出时清理资源。

# 文件目录及其余文件说明

## face_recognition_modules

人脸识别系统所有算法文件及配置文件

## model

语音识别模型文件

## models

人脸识别模型文件

## pic_register

人脸识别注册图片目录，将注册图片放入其中，系统启动时即会自动注册，注册id为图片名（不包含后缀）

## tools

人脸识别系统辅助工具

## ui

人脸识别简易GUI

## sort.py

人脸跟踪算法文件

## car_control_system_flowchart.png

系统运行流程图

## record.sqlite & registry.sqlite

人脸识别注册文件








